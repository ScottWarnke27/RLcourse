{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment Breakout doesn't exist. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=44'>45</a>\u001b[0m     plot_surface(X, Y, Z_noace, \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (No Usable Ace)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(title))\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=45'>46</a>\u001b[0m     plot_surface(X, Y, Z_ace, \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (Usable Ace)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(title))\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=47'>48</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m'\u001b[39;49m\u001b[39mBreakout-v0\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# insert your favorite environment\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=48'>49</a>\u001b[0m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=49'>50</a>\u001b[0m img \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mimshow(env\u001b[39m.\u001b[39mrender(mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/RLcourse/lib/python3.12/site-packages/gym/envs/registration.py:569\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         logger\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    564\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing the latest versioned environment `\u001b[39m\u001b[39m{\u001b[39;00mnew_env_id\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead of the unversioned environment `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m         )\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m spec_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 569\u001b[0m         _check_version_exists(ns, name, version)\n\u001b[1;32m    570\u001b[0m         \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo registered env with id: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    572\u001b[0m _kwargs \u001b[39m=\u001b[39m spec_\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/envs/RLcourse/lib/python3.12/site-packages/gym/envs/registration.py:219\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m get_env_id(ns, name, version) \u001b[39min\u001b[39;00m registry:\n\u001b[1;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m _check_name_exists(ns, name)\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RLcourse/lib/python3.12/site-packages/gym/envs/registration.py:197\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    194\u001b[0m namespace_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in namespace \u001b[39m\u001b[39m{\u001b[39;00mns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m ns \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m suggestion_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDid you mean: `\u001b[39m\u001b[39m{\u001b[39;00msuggestion[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m`?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m suggestion \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 197\u001b[0m \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mNameNotFound(\n\u001b[1;32m    198\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironment \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist\u001b[39m\u001b[39m{\u001b[39;00mnamespace_msg\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00msuggestion_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m )\n",
      "\u001b[0;31mNameNotFound\u001b[0m: Environment Breakout doesn't exist. "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import gym\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "\n",
    "EpisodeStats = namedtuple('Stats', ['episode_lengths', 'episode_rewards'])\n",
    "\n",
    "\n",
    "def plot_value_function(V, title = \"Value Function\"):\n",
    "    '''\n",
    "    Plots the value function as a surface plot.\n",
    "    '''\n",
    "    min_x = 11 # min(k[0] for k in V.keys())\n",
    "    max_x = max(k[0] for k in V.keys())\n",
    "    min_y = min(k[1] for k in V.keys())\n",
    "    max_y = max(k[1] for k in V.keys())\n",
    "\n",
    "    x_range = np.arange(min_x, max_x + 1)\n",
    "    y_range = np.arange(min_y, max_y + 1)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "    # Find value for all (x, y) coordinates\n",
    "    Z_noace = np.apply_along_axis(lambda _: V[(_[0], _[1], False)], 2, np.dstack([X, Y]))\n",
    "    Z_ace = np.apply_along_axis(lambda _: V[(_[0], _[1], True)], 2, np.dstack([X, Y]))\n",
    "\n",
    "    def plot_surface(X, Y, Z, title):\n",
    "        fig = plt.figure(figsize = (20, 10))\n",
    "        ax = fig.add_subplot(111, projection = '3d')\n",
    "        surf = ax.plot_surface(X, Y, Z, rstride = 1, cstride = 1,\n",
    "                               cmap = matplotlib.cm.coolwarm, vmin = -1.0, vmax = 1.0)\n",
    "        ax.set_xlabel('Player Sum')\n",
    "        ax.set_ylabel('Dealer Showing')\n",
    "        ax.set_zlabel('Value')\n",
    "        ax.set_title(title)\n",
    "        ax.view_init(ax.elev, -120)\n",
    "        fig.colorbar(surf)\n",
    "        plt.show()\n",
    "\n",
    "    plot_surface(X, Y, Z_noace, \"{} (No Usable Ace)\".format(title))\n",
    "    plot_surface(X, Y, Z_ace, \"{} (Usable Ace)\".format(title))\n",
    "\n",
    "#env = gym.make('Breakout-v0') # insert your favorite environment\n",
    "env.reset()\n",
    "img = plt.imshow(env.render(mode = 'rgb_array'))\n",
    "for _ in range(100):\n",
    "    img.set_data(env.render(mode = 'rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait = True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "def cmp(a, b):\n",
    "    return float(a > b) - float(a < b)\n",
    "\n",
    "# 1 = Ace, 2-10 = Number cards, Jack/Queen/King = 10\n",
    "deck = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10]\n",
    "\n",
    "\n",
    "def draw_card(np_random):\n",
    "    return int(np_random.choice(deck))\n",
    "\n",
    "\n",
    "def draw_hand(np_random):\n",
    "    return [draw_card(np_random), draw_card(np_random)]\n",
    "\n",
    "\n",
    "def usable_ace(hand):  # Does this hand have a usable ace?\n",
    "    return 1 in hand and sum(hand) + 10 <= 21\n",
    "\n",
    "\n",
    "def sum_hand(hand):  # Return current hand total\n",
    "    if usable_ace(hand):\n",
    "        return sum(hand) + 10\n",
    "    return sum(hand)\n",
    "\n",
    "\n",
    "def is_bust(hand):  # Is this hand a bust?\n",
    "    return sum_hand(hand) > 21\n",
    "\n",
    "\n",
    "def score(hand):  # What is the score of this hand (0 if bust)\n",
    "    return 0 if is_bust(hand) else sum_hand(hand)\n",
    "\n",
    "\n",
    "def is_natural(hand):  # Is this hand a natural blackjack?\n",
    "    return sorted(hand) == [1, 10]\n",
    "\n",
    "\n",
    "class BlackjackEnv(gym.Env):\n",
    "    \"\"\"Simple blackjack environment\n",
    "    Blackjack is a card game where the goal is to obtain cards that sum to as\n",
    "    near as possible to 21 without going over.  They're playing against a fixed\n",
    "    dealer.\n",
    "    Face cards (Jack, Queen, King) have point value 10.\n",
    "    Aces can either count as 11 or 1, and it's called 'usable' at 11.\n",
    "    This game is placed with an infinite deck (or with replacement).\n",
    "    The game starts with each (player and dealer) having one face up and one\n",
    "    face down card.\n",
    "    The player can request additional cards (hit=1) until they decide to stop\n",
    "    (stick=0) or exceed 21 (bust).\n",
    "    After the player sticks, the dealer reveals their facedown card, and draws\n",
    "    until their sum is 17 or greater.  If the dealer goes bust the player wins.\n",
    "    If neither player nor dealer busts, the outcome (win, lose, draw) is\n",
    "    decided by whose sum is closer to 21.  The reward for winning is +1,\n",
    "    drawing is 0, and losing is -1.\n",
    "    The observation of a 3-tuple of: the players current sum,\n",
    "    the dealer's one showing card (1-10 where 1 is ace),\n",
    "    and whether or not the player holds a usable ace (0 or 1).\n",
    "    This environment corresponds to the version of the blackjack problem\n",
    "    described in Example 5.1 in Reinforcement Learning: An Introduction\n",
    "    by Sutton and Barto (1998).\n",
    "    http://incompleteideas.net/sutton/book/the-book.html\n",
    "    \"\"\"\n",
    "    def __init__(self, natural=False):\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(32),\n",
    "            spaces.Discrete(11),\n",
    "            spaces.Discrete(2)))\n",
    "        self.seed()\n",
    "\n",
    "        # Flag to payout 1.5 on a \"natural\" blackjack win, like casino rules\n",
    "        # Ref: http://www.bicyclecards.com/how-to-play/blackjack/\n",
    "        self.natural = natural\n",
    "        # Start the first game\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        if action:  # hit: add a card to players hand and return\n",
    "            self.player.append(draw_card(self.np_random))\n",
    "            if is_bust(self.player):\n",
    "                done = True\n",
    "                reward = -1\n",
    "            else:\n",
    "                done = False\n",
    "                reward = 0\n",
    "        else:  # stick: play out the dealers hand, and score\n",
    "            done = True\n",
    "            while sum_hand(self.dealer) < 17:\n",
    "                self.dealer.append(draw_card(self.np_random))\n",
    "            reward = cmp(score(self.player), score(self.dealer))\n",
    "            if self.natural and is_natural(self.player) and reward == 1:\n",
    "                reward = 1.5\n",
    "        return self._get_obs(), reward, done, {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return (sum_hand(self.player), self.dealer[0], usable_ace(self.player))\n",
    "\n",
    "    def reset(self):\n",
    "        self.dealer = draw_hand(self.np_random)\n",
    "        self.player = draw_hand(self.np_random)\n",
    "        return self._get_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_prediction(policy, env, num_episodes, discount_factor = 1.0):\n",
    "    '''\n",
    "    Monte Carlo prediction algorithm. \n",
    "    Calculates the value function for a given policy using sampling.\n",
    "    \n",
    "    Args:\n",
    "        policy: A function that maps an observation to action probabilities.\n",
    "        env: OpenAI gym environment.\n",
    "        num_episodes: Nubmer of episodes to sample.\n",
    "        discount_factor: Lambda discount factor.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that maps from state -> value.\n",
    "        The state is a tuple and the value is a float.\n",
    "    '''\n",
    "    # Keeps track of sum and count of returns for each state\n",
    "    # to calculate an average. We could use an array to save all\n",
    "    # returns but that's memory inefficient.\n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    \n",
    "    # The final value function\n",
    "    V = defaultdict(float)\n",
    "    \n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        \n",
    "        episodes = []\n",
    "        for i in range(100):\n",
    "            action = policy(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            episodes.append((observation, action, reward))\n",
    "            if done:\n",
    "                break\n",
    "            observation = next_observation\n",
    "        \n",
    "        # obtain unique observation set\n",
    "        observations = set([x[0] for x in episodes])\n",
    "        for i, observation in enumerate(observations):\n",
    "            # first occurence of the observation\n",
    "            idx = episodes.index([episode for episode in episodes if episode[0] == observation][0])\n",
    "            \n",
    "            Q = sum([episode[2] * discount_factor ** i for episode in episodes[idx:]])\n",
    "            \n",
    "            returns_sum[observation] += Q\n",
    "            returns_count[observation] += 1.0\n",
    "            \n",
    "            V[observation] = returns_sum[observation] / returns_count[observation]\n",
    "                \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "env = gym.make('Blackjack-v1')\n",
    "\n",
    "# A policy that sticks if the player score is >= 20 and hits otherwise.\n",
    "def sample_policy(observation):\n",
    "    score, dealer_score, usable_ace = observation\n",
    "    return 0 if score >= 20 else 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m V_10k \u001b[39m=\u001b[39m mc_prediction(sample_policy, env, num_episodes \u001b[39m=\u001b[39;49m \u001b[39m10000\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m plot_value_function(V_10k, title \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m10000 Steps\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m V_500k \u001b[39m=\u001b[39m mc_prediction(sample_policy, env, num_episodes \u001b[39m=\u001b[39m \u001b[39m500000\u001b[39m)\n",
      "\u001b[1;32mUntitled-1.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=28'>29</a>\u001b[0m episodes \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=30'>31</a>\u001b[0m     action \u001b[39m=\u001b[39m policy(observation)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=31'>32</a>\u001b[0m     next_observation, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=32'>33</a>\u001b[0m     episodes\u001b[39m.\u001b[39mappend((observation, action, reward))\n",
      "\u001b[1;32mUntitled-1.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_policy\u001b[39m(observation):\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m     score, dealer_score, usable_ace \u001b[39m=\u001b[39m observation\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m score \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m20\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "V_10k = mc_prediction(sample_policy, env, num_episodes = 10000)\n",
    "plot_value_function(V_10k, title = '10000 Steps')\n",
    "\n",
    "V_500k = mc_prediction(sample_policy, env, num_episodes = 500000)\n",
    "plot_value_function(V_500k, title = '500000 Steps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
